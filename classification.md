# 分類（Classification）
- データを離散的なカテゴリに分類

## **1. 線形分類**
- **ロジスティック回帰（Logistic Regression）**  
  - 2クラス分類において、確率的な出力を得るために使用。
  - **多クラス分類**には、One-vs-AllやSoftmax回帰を利用。

- **線形判別分析（Linear Discriminant Analysis, LDA）**  
  - 特徴量がガウス分布に従うと仮定した場合に有効。
  - 主に2クラスまたは多クラス分類に利用。

## **2. 非線形分類**
- **サポートベクターマシン（Support Vector Machine, SVM）**  
  - 高次元空間でデータを線形分離するための手法。
  - **カーネルトリック**を使うことで非線形の分類も可能。

- **決定木（Decision Tree）**  
  - データを条件ごとに分岐させていき、分類する。
  - 過学習しやすいため、**剪定（Pruning）**が重要。

- **ランダムフォレスト（Random Forest）**  
  - 複数の決定木を組み合わせて予測を行うアンサンブル学習法。
  - 特徴量の重要度を評価できる。

- **勾配ブースティング（Gradient Boosting）**  
  - 弱い予測器（決定木）を順次学習させていき、最終的な予測を改善する。
  - **XGBoost**や**LightGBM**などが有名。

## **3. ニューラルネットワーク**
- **パーセプトロン（Perceptron）**  
  - 単純な1層のニューラルネットワーク。線形分類に使用。
  
- **多層パーセプトロン（MLP, Multi-Layer Perceptron）**  
  - 隠れ層を持つニューラルネットワークで、非線形な分類にも対応。

- **畳み込みニューラルネットワーク（CNN, Convolutional Neural Network）**  
  - 主に画像分類に使用されるが、テキスト分類にも応用可能。

- **リカレントニューラルネットワーク（RNN, Recurrent Neural Network）**  
  - 時系列データやシーケンスデータ（例: テキスト、音声）の分類に利用。
  - **LSTM**や**GRU**が時間的依存関係を扱う。

## **4. ベイズ的手法**
- **ナイーブベイズ（Naive Bayes）**  
  - 各特徴量が独立であると仮定する。テキスト分類などでよく使用。
  - **ガウス分布**や**多項分布**など、データに適した分布を仮定する。

## **5. クラスタリングを応用した分類**
- **k-近傍法（k-Nearest Neighbors, k-NN）**  
  - クラスラベルが付与されたデータに基づいて、最も近いk個のデータからクラスを予測。

- **k-meansクラスタリング**  
  - 分類タスクには使われないが、**クラスタリング**の結果を基にラベルを付けて分類問題に応用されることも。

## **6. その他**
- **強化学習による分類（Reinforcement Learning Classification）**  
  - 特定の目的に応じて、環境とのインタラクションを通じて分類タスクを学習。

- **カスタムメトリクスによる最適化（Custom Metric Optimization）**  
  - 特定の目的関数を定義し、それを最適化する分類器を設計する方法。

---

# 利用が特定される状況の例

- **ロジスティック回帰**：二項分類や多クラス分類に使用。シンプルで解釈がしやすい。
- **SVM**：小さなデータセットで高精度な分類を目指す。
- **決定木・ランダムフォレスト**：複雑な分類問題で特徴量の重要度評価が必要な場合。
- **勾配ブースティング（XGBoost, LightGBM）**：高い予測精度が求められる場合。
- **ニューラルネットワーク（CNN、RNN）**：画像分類やテキスト分類など、深層学習を利用した複雑な分類タスク。
