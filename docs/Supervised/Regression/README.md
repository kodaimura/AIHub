# 回帰 (Regression)

回帰は、連続的な数値を予測することを目的とした教師あり学習の一分野。

---

## 主な回帰手法

### 1. 線形回帰 (Linear Regression)
**特徴**:  
- 最も基本的な回帰手法。入力変数と出力変数の間の線形関係を仮定する。  
- 高速で解釈が容易。  

**適用例**:  
- 価格の予測 (不動産、商品の価格など)  
- 単純な関係性が予測に十分である場合  

---

### 2. リッジ回帰 (Ridge Regression)
**特徴**:  
- 線形回帰に正則化項を追加した手法。過学習を防ぐ。  
- 高次元データに適している。  

**適用例**:  
- 説明変数が多く、共線性がある場合  
- モデルの単純さと精度のバランスを取りたい場合  

---

### 3. ラッソ回帰 (Lasso Regression)
**特徴**:  
- リッジ回帰と同様に正則化を行うが、特徴選択も同時に行う。  
- 一部の係数をゼロにして不要な特徴量を除外する。  

**適用例**:  
- 高次元データで、不要な特徴量を自動的に削減したい場合  

---

### 4. 多項式回帰 (Polynomial Regression)
**特徴**:  
- 線形回帰の入力変数を多項式に変換することで、非線形な関係を表現可能。  
- 非線形の関係を捉えたい場合に使用する。  

**適用例**:  
- データが明らかに非線形のパターンを示す場合  

---

### 5. サポートベクター回帰 (Support Vector Regression, SVR)
**特徴**:  
- サポートベクターマシンを基にした回帰手法。  
- ロバスト性が高く、線形/非線形の関係を捉えられる。  

**適用例**:  
- データに外れ値が多い場合  
- 複雑な非線形関係を捉えたい場合  

---

### 6. 決定木回帰 (Decision Tree Regression)
**特徴**:  
- データを分割して予測を行うモデル。  
- 非線形データに強く、直感的に理解しやすい。  

**適用例**:  
- データの非線形性が強い場合  
- 変数間の相互作用が重要な場合  

---

### 7. ランダムフォレスト回帰 (Random Forest Regression)
**特徴**:  
- 複数の決定木を使用して予測精度を向上させる手法。  
- 過学習しにくい。  

**適用例**:  
- 高次元かつ非線形のデータ  
- モデルの精度を優先したい場合  

---

### 8. ブースティング回帰 (Boosting Regression)
**特徴**:  
- 複数の弱い学習器を組み合わせて、強力な予測モデルを構築する。  
- 精度が非常に高いが、計算コストが高い場合もある。  

**適用例**:  
- 精度が最優先されるタスク  
- 学習データが大量に存在する場合  

---

### 9. ニューラルネットワーク回帰 (Neural Network Regression)
**特徴**:  
- 多層のパラメータを使用して、非常に複雑な非線形関係をモデル化する。  
- 計算コストが高いが、高い予測精度を得られる場合がある。  

**適用例**:  
- 非線形かつ複雑なデータのモデリング  
- 画像やテキストなどの構造化データを扱う場合  

---

## 回帰手法の選び方

1. **データの関係性**  
   - **線形関係の場合**: 線形回帰やリッジ回帰  
   - **非線形関係の場合**: 多項式回帰、SVR、決定木回帰など  

2. **次元の多さ**  
   - **特徴量が多い場合**: リッジ回帰やラッソ回帰  

3. **精度と計算コストのバランス**  
   - **高速かつシンプルなモデルが必要**: 線形回帰や決定木回帰  
   - **高精度が必要**: ランダムフォレスト回帰やブースティング回帰  

4. **データの量**  
   - **大量のデータがある場合**: ニューラルネットワーク回帰やブースティング回帰  
   - **データが少ない場合**: 決定木回帰やSVR  
