# 分類 (Classification)

分類は、ラベル付きデータを用いて、新しいデータを特定のカテゴリやラベルに分類することを目的とした教師あり学習の一分野。

---

## 主な分類手法

### 1. ロジスティック回帰 (Logistic Regression)
**特徴**:  
- 線形モデルの一種で、確率的な出力を生成する。  
- 単純で実装が容易。  

**適用例**:  
- 二値分類 (例: スパムメール検出、疾患の有無)  
- 線形分離可能なデータ  

---

### 2. サポートベクターマシン (Support Vector Machine, SVM)
**特徴**:  
- 最大マージンで分離する分類器。  
- 線形および非線形分類が可能 (カーネル手法を利用)。  

**適用例**:  
- 高次元データ  
- クラス間の境界が明確な場合  

---

### 3. k近傍法 (k-Nearest Neighbors, k-NN)
**特徴**:  
- データの類似性に基づいて分類を行う。  
- 非線形の関係も扱えるが、大量データでは計算コストが高い。  

**適用例**:  
- パターン認識 (画像分類、音声分類)  
- データが少量かつ構造が単純な場合  

---

### 4. 決定木分類 (Decision Tree Classification)
**特徴**:  
- データを分割して予測を行うモデル。  
- 解釈が容易で、非線形データに強い。  

**適用例**:  
- 説明性が重要な場合  
- データの非線形性が強い場合  

---

### 5. ランダムフォレスト分類 (Random Forest Classification)
**特徴**:  
- 複数の決定木を組み合わせたアンサンブル学習。  
- 過学習に強く、高い汎化性能を持つ。  

**適用例**:  
- 高次元データ  
- モデルの精度を重視するタスク  

---

### 6. ブースティング分類 (Boosting Classification)
**特徴**:  
- 弱い学習器を組み合わせて強力なモデルを作成。  
- 高い精度を持つが、計算コストが高い場合がある。  

**適用例**:  
- 精度が最優先されるタスク  
- 大量の学習データが利用可能な場合  

---

### 7. ナイーブベイズ分類 (Naive Bayes Classification)
**特徴**:  
- 条件付き確率に基づくモデル。  
- 単純だが、多くの場合で有効に機能する。  

**適用例**:  
- テキスト分類 (スパムフィルタ、感情分析)  
- 独立性の仮定が大きく外れていない場合  

---

### 8. ニューラルネットワーク分類 (Neural Network Classification)
**特徴**:  
- 多層パラメータを用いて複雑な非線形関係をモデル化。  
- 高い予測精度を得られるが、計算リソースが必要。  

**適用例**:  
- 画像や音声、テキスト分類などの複雑なタスク  
- 大量の学習データがある場合  

---

### 9. k-平均法 (k-Means Clustering) + 分類
**特徴**:  
- クラスタリングで得られたラベルを分類に利用する。  
- ラベル付きデータが少ない場合の補助的な手法。  

**適用例**:  
- ラベルのないデータから潜在的な構造を発見  
- データの事前探索  

---

## 分類手法選択ガイド

1. **データは線形関係にありますか？**
   - はい → **ロジスティック回帰**（線形分類、確率的な出力）
   - いいえ → 次へ

2. **非線形関係が必要ですか？**
   - はい → **ブースティング分類**（精度重視、データ量と計算リソースが豊富）
   - いいえ → **ランダムフォレスト分類**

3. **特徴量は多いですか？**
   - はい → 高次元データに強い手法が必要
     - はい → **サポートベクターマシン（SVM）**
     - いいえ → **ランダムフォレスト分類**
   - いいえ → 次へ

4. **非線形性を捉えたいですか？**
   - はい → **決定木分類**
   - いいえ → **k近傍法（k-NN）**（シンプルで少ないデータでも有効）

5. **データ量が非常に多く、計算リソースが豊富ですか？**
   - はい → **ニューラルネットワーク分類**（非常に複雑で非線形なデータに対応）
   - いいえ → 上記手法から選択