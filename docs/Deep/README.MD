# 深層学習 (Deep Learning)

深層学習は、人工ニューラルネットワークを基盤にした学習手法で、複雑なパターンや特徴を自動的に学習することができます。大量のデータと計算リソースを活用して、高度な予測や分類を実現します。

---

## 主なカテゴリ

### 1. 畳み込みニューラルネットワーク (Convolutional Neural Networks, CNN)  
主に画像データの解析に使用されるニューラルネットワークで、画像の特徴を効率的に抽出し、分類や物体検出を行う。

**例**:  
- 画像認識  
- 物体検出  
- 顔認識  
- 自動運転車の視覚システム  

---

### 2. 再帰型ニューラルネットワーク (Recurrent Neural Networks, RNN)  
時系列データやシーケンシャルデータに特化したニューラルネットワークで、前の時点の出力を次の時点の入力に組み込む。

**例**:  
- 音声認識  
- 自然言語処理 (NLP)  
- 機械翻訳  
- 時系列予測 (株価、天気予報など)  

---

### 3. 長短期記憶 (Long Short-Term Memory, LSTM)  
RNNの拡張で、長期的な依存関係を学習する能力を強化したネットワーク。長いシーケンスデータでも有効。

**例**:  
- 音声合成  
- 自然言語生成  
- 動作認識  
- 機械翻訳  

---

### 4. 生成対向ネットワーク (Generative Adversarial Networks, GAN)  
生成モデルと識別モデルの二つのネットワークが競い合いながら学習を進め、リアルなデータを生成することを目指す手法。

**例**:  
- 画像生成 (顔画像、風景画像など)  
- 画像修復  
- 映像生成  
- アートの生成  

---

### 5. 自己符号化器 (Autoencoders)  
入力データを圧縮して特徴を抽出し、再構成するニューラルネットワークで、次元削減や特徴抽出に利用される。

**例**:  
- データ圧縮  
- 異常検知  
- ノイズ除去  
- 特徴抽出  

---

### 6. 強化学習 (Reinforcement Learning)  
エージェントが環境とインタラクションを通じて報酬を得ながら最適な行動を学習する手法。深層学習を用いて価値関数や政策を学習する。

**例**:  
- ゲームAI (チェス、囲碁、ビデオゲーム)  
- 自律ロボットの制御  
- 自動運転車の制御  
- ポートフォリオ最適化  

---

### 7. トランスフォーマー (Transformers)  
自己注意機構を基盤としたモデルで、特に自然言語処理において非常に高い性能を発揮する。BERTやGPTなどのアーキテクチャが有名。

**例**:  
- 機械翻訳  
- 自然言語理解 (NLP)  
- 文書生成  
- 質問応答システム  

---

### 8. 深層強化学習 (Deep Reinforcement Learning)  
深層学習と強化学習を組み合わせた手法で、画像や音声などの複雑な入力を処理しながら、エージェントが環境とインタラクションを通じて学習を行う。

**例**:  
- 自律走行車の制御  
- ドローンの自動制御  
- ゲームAI  
- 産業ロボットの自動化  