# クラスタリング (Clustering)

クラスタリングは、データを似た特徴を持つグループに分けることを目的とした教師なし学習の一分野。

---

## 主なクラスタリング手法

### 1. k-meansクラスタリング
- **特徴**: データをk個のクラスタに分ける。各クラスタの重心（平均）を基にデータを割り当て。
- **適用例**: 単純なクラスタリング問題、ドキュメント分類。

### 2. 階層的クラスタリング (Hierarchical Clustering)
- **特徴**: データポイントを階層的にグループ化する手法。最初は各データポイントを1つのクラスタとして扱い、最も近いクラスタ同士を統合していく。
- **適用例**: 進化学、階層的なグループ化が必要な場合。

### 3. DBSCAN (Density-Based Spatial Clustering of Applications with Noise)
- **特徴**: 密度に基づいてクラスタを形成。データ密度が高い領域をクラスタとして扱い、低密度領域を外れ値として扱う。
- **適用例**: ノイズが多いデータセット、形が不規則なクラスタ。

### 4. Gaussian Mixture Model (GMM)
- **特徴**: 各クラスタがガウス分布に従うと仮定し、EMアルゴリズムを使って最適な分布を求める。
- **適用例**: データが連続的で、分布が正規分布に近い場合。

### 5. 自己組織化マップ (Self-Organizing Map, SOM)
- **特徴**: 高次元データを低次元（通常2次元）のグリッドにマッピングし、似たデータを近くに配置する。
- **適用例**: 高次元データの可視化、クラスタリング。

### 6. t-SNE (t-Distributed Stochastic Neighbor Embedding)
- **特徴**: 高次元データを2次元または3次元に埋め込むことで、データの局所的な構造を保存する。
- **適用例**: データ可視化、データのパターン認識。

### 7. Affinity Propagation
- **特徴**: クラスタを形成するために、データ間の類似度を基にクラスタの中心を決定する。事前にクラスタ数を指定しない。
- **適用例**: クラスタ数を事前に設定できない場合。

### 8. Mean Shift
- **特徴**: データの密度が最も高い方向にシフトしていくことでクラスタを発見する非線形なクラスタリング手法。
- **適用例**: ノイズが多いデータや、複数の異なる密度を持つクラスタ。

### 9. Spectral Clustering
- **特徴**: データの類似度行列を使って、グラフ理論を用いてクラスタリングを行う手法。
- **適用例**: 複雑なデータ構造や、非線形なクラスタリングが必要な場合。

---

## クラスタリング手法選択ガイド

1. **データに明確なクラスタ数はありますか？**
   - はい → **k-meansクラスタリング**
   - いいえ → 次へ

2. **データにノイズや外れ値がありますか？**
   - はい → **DBSCAN**
   - いいえ → 次へ

3. **データがガウス分布に従っていると思いますか？**
   - はい → **Gaussian Mixture Model (GMM)**
   - いいえ → 次へ

4. **クラスタの形状が不規則である場合、あるいは階層的な構造を見たいですか？**
   - はい → **階層的クラスタリング**
   - いいえ → **k-meansクラスタリング**

5. **データの可視化や高次元データの分析が必要ですか？**
   - はい → **自己組織化マップ (SOM)** または **t-SNE**
   - いいえ → 上記手法から選択
